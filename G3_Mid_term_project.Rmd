---
title: "2022 Mid term project- Unemployment Insurance descincentivazation to seek employment"
author: "Group_3 Dustin Riles, Nina Ebensperger,Alejandra Mejia"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: yes
    always_allow_html: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    toc: yes
    toc_depth: '3'
    urlcolor: blue
---

```{r init, include=F}
# The package "panelr" was included in order to get sumamry statistics in using panel data

#tinytex::install_tinytex()
library(ezids)
library(plot3D)
library(tinytex)

#install.packages("dplyr")      
#install.packages("plyr")       
#install.packages("readr")   
#installed.packages('skimr', repos = "http://cran.us.r-project.org")
#install.packages
#install.packages("panelr")

library(panelr)
library(dplyr)
library(plyr)
library(readr)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	results = "hide"
)

options(scientific=T, digits = 3) 
```

# The Pandemic and the Unemployment Insurance
## The beginning


[Edition requiered]In the past 20 years, the world has experienced two great economic catastrophes. The first of those, The Great Recession of 2008, was caused by a myriad of factors, but at the center of it all was a failure of
institutions. The 2020 recession caused by the COVID-19 Pandemic was of a different nature. The world put the economy on hold in order to protect global health. Regardless of the cause, ordinary citizens felt the impact of each recession. One of the main ways this is seen is through the unemployment rate. In April 2020, the United States reached a previously unseen level of 14.7 percent. While the unemployment rate did not skyrocket quite as high during the Great Recession, there was still a sizeable increase. During both recessions, the federal government authorized enhanced and extended unemployment insurance benefits.

While necessary for many to keep afloat during the economic crises, a potential drawback of this policy is that workers may be disincentivized to work. If the benefit level is sufficiently high, returning to work may pay less money than remaining on unemployment insurance. A rational actor would see this and decide to stay on unemployment insurance and not return to the workforce. We seek to explore this topic and examine if workers were disincentivized to return to work. See photo:  
 ![Unemployment Insurance](C:/Users/apmej/OneDrive/Escritorio/R/UI_image.jpeg)


## About the data

The weekly Census Household Pulse Survey, which collects data from an average of around 97,000 respondents per week. The details for the dataset can be found here:
https://www.census.gov/programs-surveys/household-pulse-survey/datasets.html. The main reasons we used this data includes: .........










Let us now merge and use the big data dataset using R.


```{r init_data}

# Setting working directory
setwd('C:\\Users\\apmej\\OneDrive\\Escritorio\\R\\Data\\')

#import and merge all CSV files into one data frame

df <- list.files(path='C:/Users/apmej/OneDrive/Escritorio/R/Data') %>% 
  lapply(read_csv) %>% 
  bind_rows 

# remove additional unnecesary rows
df2 <- df[ -c(4:5,26:51) ]

#installing panel data indicators

df_panel<- panel_data(df2, id = SCRAM, wave = WEEK)
head(df_panel)

```

So there are `  ` data points in our dataset. (Notice the use of inline R codes here.)

## Exploratory Data Analysis (EDA)

Mention what type of variables are going to be evaluated and why




### Basic statistics
```{r EDA_basicstats, results='asis'}
#str(df_panel)
summary.data.frame(df_panel)
```

What can we get from the data?

```{r EDA_rerun, results="asis"}

## rerun when we have corrected data



```

### Tests (Correlation, ANOVA, ...)
Which test are we doing an why?

```{r corr, echo=T, message=F}
#Run test and plot

#loadPkg("corrplot")
#corrmatrix = cor(kfcw)  # more detailed pair-wise correlation test can be obtained from cor.test(kfcw$wing,kfcw$price) etc
#corrplot.mixed(corrmatrix, 
#               title="Correlation Matrix for Chicken Meal Price",
#               mar=c(0,0,1,0) # fixes the position of title
#               )
```

What we found?

### Normality check/test
what we found?

#### QQ-plot
Why we are using this method
```{r normality_qqplot, echo=T}
#qnorm(kfcw$price, main = "Price Q-Q Plot", ylab="Price Quantiles ($)") 
#qline(kfcw$price)
#qnorm(kfcw$wing, main = "Wing Q-Q Plot", ylab="Wing-count Quantiles") 
#qline(kfcw$wing)
#qnorm(kfcw$drum, main = "Drum Q-Q Plot", ylab="Drum-count Quantiles") 
#qline(kfcw$drum)
```

what we found
#### Boxplot
WHy?
```{r normality_boxplot, echo=T}
# We will learn to use the more powerful ggplot soon, instead of this generic boxplot function
#boxplot(kfcw, col=c("red","blue","green"), ylab="count or price($)", main="Boxplots for the three variables")
#axis(side = 4)
```

Same conclusion: they do not look like normal, but we'll take it.

#### Histogram
Now histograms:
```{r normality_histogram, echo=T}
# We will learn to use the more powerful ggplot soon, instead of this generic hist function for histograms
#barcolors = c("green", "violet", "orange", "blue", "pink", "red", "yellow", "cyan")
#hist(kfcw$price, main = "Histogram for Price distribution", xlab="Price ($)", col=barcolors, breaks = 10)
#hist(kfcw$wing, main = "Histogram for Wing-count", xlab="Wing Count", col=barcolors, breaks = 6)
#hist(kfcw$drum, main = "Histogram for Drum-count", xlab="Drum Count", col=barcolors, breaks = 6)
```

#### Shapiro-Wilk test
And finally, using shapiro-wilk test:
```{r normality_shapiro_wilk}
#priceshapiro = shapiro.test(kfcw$price)
#wingshapiro = shapiro.test(kfcw$wing)
#drumshapiro = shapiro.test(kfcw$drum)
```


## Linear Model

Why?

```{r linear_model, results=T}
# build a simple linear model (least square fit) of price as a function of everything else.
#chicklm = lm(price ~ ., data=kfcw)
# summary(chicklm)
#xkabledply(chicklm, title = "Summary of linear model for Chicken Meals")
```


```{r confint.lm, results=T}
#coeffconfint = confint.lm(chicklm) 
# coeffconfint
#xkabledply(coeffconfint, title = "Coefficient Confidence Intervals (CI) at 95%") # display better than the line above
```

### Findings
We find that:

Check:   


```{r linearmodel_vif, results=T}
#loadPkg("faraway") # faraway library is one of them has a vif function
# VIF check the collinearity issues between different variables/features in a (linear) model
# vif(chicklm)
#xkablevif(chicklm, title="Chicken Model VIFs")  # better display than the line above
# unloadPkg("faraway")
```
With VIF values less than 5, we can safely conclude there is not much collinearity concerns in the dataset. 

### Plot 3D
What kind of plot

```{r 3dscatter2, echo=T}
#loadPkg("plot3D")
# reference from http://www.sthda.com/english/wiki/impressive-package-for-3d-and-4d-graph-r-software-and-data-visualization
# x, y, z variables
#x <- kfcw$wing
#y <- kfcw$drum
#z <- kfcw$price
# Compute the linear regression (z = ax + by + d)
# chicklm <- lm(z ~ x + y)
# predict values on regular xy grid
#grid.lines = 20
#x.pred <- seq(min(x), max(x), length.out = grid.lines)
#y.pred <- seq(min(y), max(y), length.out = grid.lines)
#xy <- expand.grid( wing = x.pred, drum =y.pred)
#z.pred <- matrix(predict.lm(chicklm, newdata = xy), nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
#fitpoints <- predict.lm(chicklm)
# scatter plot with regression plane
#scatter3D(x, y, z, pch = 18, cex = 2, theta = 5, phi = 20, ticktype = "detailed", xlab = "wing", ylab = "drum", zlab = "price",  surf = list(x = x.pred, y = y.pred, z = z.pred, facets = NA, fit = fitpoints), main = "Chicken Price Analysis")

```

# Conclusion
Conclusions???


##Limitations





## Next Steps

# Reference 

APA Style preferred



